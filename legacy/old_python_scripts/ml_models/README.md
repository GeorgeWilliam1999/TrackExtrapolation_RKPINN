# ML-Based Track Extrapolators

Machine learning models that replace traditional numerical integration for LHCb track extrapolation.

---

## ğŸ“Š Current Status

### âœ… Available Models (7 total)

All models trained on 50K samples, tested on 10K held-out validation set.

#### Activation Function Study (3 models)
| Model | Activation | Mean Error | P95 Error | Status |
|-------|------------|------------|-----------|--------|
| `mlp_act_silu.pt` | SiLU â­ | **0.21 mm** | **0.54 mm** | **BEST** |
| `mlp_act_tanh.pt` | Tanh | 0.63 mm | 1.68 mm | Baseline |
| `mlp_act_relu.pt` | ReLU | 0.77 mm | 1.78 mm | Good |

**Recommendation:** Use SiLU activation for all future models.

#### Physics-Informed Models (4 models)
| Model | Lambda (Î») | Mean Error | P95 Error | Status |
|-------|------------|------------|-----------|--------|
| `pinn_lambda_0_01.pt` | 0.01 | 18.8 mm | 47.2 mm | âŒ Failed |
| `pinn_lambda_0_05.pt` | 0.05 | 106.7 mm | 273.8 mm | âŒ Failed |
| `pinn_lambda_0_1.pt` | 0.1 | 197.2 mm | 506.7 mm | âŒ Failed |
| `pinn_lambda_0_2.pt` | 0.2 | 328.9 mm | 843.9 mm | âŒ Failed |

**Conclusion:** Current PINN formulation does not work. Physics loss conflicts with true magnetic field dynamics. See [model_investigation.ipynb](../model_investigation.ipynb) for detailed analysis.

### â³ Missing Models (Architecture Study)

These were intended to be trained but HTCondor jobs appear incomplete:
- `mlp_tiny.pt` - 64-32 architecture
- `mlp_small.pt` - 128-64 architecture  
- `mlp_medium.pt` - 128-128-64 (default)
- `mlp_large.pt` - 256-256-128-64
- `mlp_xlarge.pt` - 512-512-256-128

**Next Step:** Re-run architecture training jobs on cluster.

---

## ğŸ“‚ Directory Structure

```
ml_models/
â”‚
â”œâ”€â”€ README.md                           # This file
â”‚
â”œâ”€â”€ data/                               # Training datasets
â”‚   â”œâ”€â”€ X_analysis.npy                  # 50K training samples (6D input @ z=4000mm)
â”‚   â”œâ”€â”€ Y_analysis.npy                  # 50K targets (4D output @ z=12000mm)
â”‚   â”œâ”€â”€ P_analysis.npy                  # Momentum for each track
â”‚   â”œâ”€â”€ X_weighted_train.npy            # Legacy weighted data
â”‚   â”œâ”€â”€ Y_weighted_train.npy
â”‚   â””â”€â”€ P_weighted_train.npy
â”‚
â”œâ”€â”€ models/                             # Trained models
â”‚   â”œâ”€â”€ analysis/                       # Latest analysis models
â”‚   â”‚   â”œâ”€â”€ mlp_act_silu.pt             # Best model (0.21mm)
â”‚   â”‚   â”œâ”€â”€ mlp_act_tanh.pt
â”‚   â”‚   â”œâ”€â”€ mlp_act_relu.pt
â”‚   â”‚   â”œâ”€â”€ pinn_lambda_0_01.pt
â”‚   â”‚   â”œâ”€â”€ pinn_lambda_0_05.pt
â”‚   â”‚   â”œâ”€â”€ pinn_lambda_0_1.pt
â”‚   â”‚   â”œâ”€â”€ pinn_lambda_0_2.pt
â”‚   â”‚   â””â”€â”€ *_metadata.json             # Training metadata for each model
â”‚   â”‚
â”‚   â”œâ”€â”€ production/                     # Production models (for deployment)
â”‚   â”‚   â””â”€â”€ (empty - pending training)
â”‚   â”‚
â”‚   â”œâ”€â”€ mlp_model_cpp_v2.bin            # Legacy C++ format
â”‚   â”œâ”€â”€ pinn_model_true.bin
â”‚   â”œâ”€â”€ config.json                     # Model configuration
â”‚   â””â”€â”€ full_domain_results.json        # Benchmark results
â”‚
â”œâ”€â”€ python/                             # Training scripts
â”‚   â”œâ”€â”€ generate_training_data.py       # â­ Fast parallel data generation
â”‚   â”œâ”€â”€ train_analysis_models.py        # Train all analysis variants
â”‚   â”œâ”€â”€ train_on_gpu.py                 # General GPU training
â”‚   â”œâ”€â”€ full_domain_training.py         # Full momentum range
â”‚   â”œâ”€â”€ train_pinn.py                   # PINN training (deprecated)
â”‚   â”œâ”€â”€ train_true_pinn.py              # True PINN (deprecated)
â”‚   â”œâ”€â”€ compare_models.py               # Model comparison
â”‚   â””â”€â”€ test_pinn_simple.py             # Simple test script
â”‚
â”œâ”€â”€ condor/                             # HTCondor cluster jobs
â”‚   â”œâ”€â”€ README.md                       # Cluster usage guide
â”‚   â”œâ”€â”€ train_production.sub            # Production model training
â”‚   â”œâ”€â”€ train_analysis.sub              # Analysis model training
â”‚   â”œâ”€â”€ generate_data.sub               # Parallel data generation
â”‚   â”œâ”€â”€ *.sh                            # Job scripts
â”‚   â””â”€â”€ logs/                           # Job outputs
â”‚
â”œâ”€â”€ src/                                # C++ implementation
â”‚   â””â”€â”€ TrackMLPExtrapolator.cpp        # LHCb integration (prototype)
â”‚
â””â”€â”€ docs/                               # Additional documentation
```

---

## ğŸš€ Quick Start

### 1. Load and Use Existing Models

See [model_investigation.ipynb](../model_investigation.ipynb) for comprehensive analysis of all available models.

```python
import torch

# Load best model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = torch.load('models/analysis/mlp_act_silu.pt', map_location=device)
model.eval()

# Make predictions
with torch.no_grad():
    predictions = model(input_tensor)  # input: [N, 6], output: [N, 4]
```

### 2. Generate Training Data

Fast parallel data generation using the Runge-Kutta extrapolator:

```bash
cd python

# Generate 50K samples for analysis (takes ~5-10 min)
python generate_training_data.py \
    --samples 50000 \
    --output ../data/ \
    --name analysis

# Generate larger dataset for production (takes ~30 min for 500K)
python generate_training_data.py \
    --samples 500000 \
    --output ../data/ \
    --name production
```

**Output:**
- `X_analysis.npy` - Input states (N Ã— 6: x, y, tx, ty, q/p, z)
- `Y_analysis.npy` - Target states (N Ã— 4: x', y', tx', ty')
- `P_analysis.npy` - Momentum values (N)

### 3. Train Models Locally

#### Train all analysis variants (recommended for experiments)
```bash
cd python
python train_analysis_models.py
```

This trains:
- 5 architecture variants (tiny, small, medium, large, xlarge)
- 3 activation variants (tanh, relu, silu)
- 4 PINN variants (Î» = 0.01, 0.05, 0.1, 0.2)

**Time:** ~20-30 min on GPU for all 12 models

#### Train single custom model
```bash
python train_on_gpu.py \
    --hidden 256 256 128 64 \
    --activation silu \
    --epochs 2000 \
    --lr 0.001 \
    --name my_custom_model
```

### 4. Submit Cluster Jobs (HTCondor)

For large-scale training on GPU cluster:

```bash
cd condor

# Generate large training dataset (parallel jobs)
condor_submit generate_data.sub

# Train all production models
condor_submit train_production.sub

# Monitor jobs
condor_q

# Check specific job output
tail -f logs/prod_medium_*.out
```

See [condor/README.md](condor/README.md) for detailed cluster documentation.

---

## ğŸ§  Model Architecture

### Network Structure

**TrackMLP** (Data-Driven)
```
Input (6D):  x, y, tx, ty, q/p, z
              â†“
Hidden:      [128] â†’ [128] â†’ [64]  (configurable)
Activation:  SiLU (best), tanh, ReLU
              â†“
Output (4D): x', y', tx', ty'
```

**TrackPINN** (Physics-Informed - deprecated)
```
Same architecture as MLP but with additional physics loss:
  L_total = L_MSE + Î» Ã— L_physics
  
  L_physics = L_position + L_bending + L_ty_penalty
```

### Input Features (6D @ z = 4000 mm)
1. **x** [mm] - Horizontal position
2. **y** [mm] - Vertical position
3. **tx** - Horizontal slope (dx/dz)
4. **ty** - Vertical slope (dy/dz)
5. **q/p** [GeVâ»Â¹] - Signed inverse momentum
6. **z** [mm] - Longitudinal position (currently fixed at 4000)

### Output Features (4D @ z = 12000 mm)
1. **x'** [mm] - Extrapolated horizontal position
2. **y'** [mm] - Extrapolated vertical position
3. **tx'** - Extrapolated horizontal slope
4. **ty'** - Extrapolated vertical slope

### What the Network Learns

The network implicitly learns:
- âœ… Non-uniform magnetic field B(x, y, z) effects
- âœ… Lorentz force curvature: F = q(v Ã— B)
- âœ… Momentum-dependent bending
- âœ… Geometric path length corrections
- âœ… Charge-dependent deflection (+/- bending)

All without explicit physics equations - just from 50K examples!

---

## ğŸ“ˆ Training Details

### Data Generation
- **Source:** LHCb Gaudi framework (`TrackRungeKuttaExtrapolator`)
- **Method:** Parallel processes (multiprocessing)
- **Coverage:** Full phase space
  - Momentum: 0.5 - 100 GeV/c
  - Position: Â±1000 mm (x, y)
  - Slopes: Â±0.3 (tx, ty)
  - Charge: Both +/- particles
- **Propagation:** z = 4000 mm â†’ 12000 mm (Î”z = 8000 mm)

### Training Configuration
- **Framework:** PyTorch 2.9.1 + CUDA 12.8
- **Loss:** Mean Squared Error (MSE)
  ```python
  loss = F.mse_loss(predictions, targets)
  ```
- **Optimizer:** AdamW
  - Learning rate: 0.001 (initial)
  - Weight decay: 1e-5
- **Scheduler:** ReduceLROnPlateau
  - Factor: 0.5
  - Patience: 50 epochs
  - Min LR: 1e-6
- **Batch size:** 1024
- **Epochs:** 2000 (with early stopping)
- **Hardware:** NVIDIA L40S GPU (45GB VRAM)
- **Time:** 2-5 minutes per model on GPU

### Evaluation Metrics
- **Position Error:** $\text{err} = \sqrt{(x' - x_{true})^2 + (y' - y_{true})^2}$
- **Slope Error:** $\|\Delta \mathbf{t}\| = \sqrt{(\Delta t_x)^2 + (\Delta t_y)^2}$
- **Statistics:** Mean, Median, P95, Max

---

## âš ï¸ Known Issues

### 1. PINN Models Failed
**Problem:** All PINN variants have 10-1000Ã— worse error than baseline MLP.

**Root Cause:** Physics loss formulation is oversimplified
- Assumes straight-line propagation between collocation points
- Doesn't properly integrate Lorentz force ODE
- Conflicts with true magnetic field dynamics

**Evidence:** See detailed autograd analysis in [model_investigation.ipynb](../model_investigation.ipynb)

**Solution:** Either:
- Abandon PINNs (current recommendation - data-driven works!)
- Redesign with proper ODE integration using Neural ODEs
- Add collocation points along actual trajectory

### 2. Architecture Models Missing
**Problem:** Only activation study models exist, no architecture variants.

**Cause:** HTCondor jobs may have failed or not completed.

**Solution:** Re-run `condor/train_analysis.sub` or train locally with `python/train_analysis_models.py`

### 3. Limited Momentum Range
**Current:** 0.5 - 100 GeV/c  
**LHCb Full Range:** 0.5 - 200 GeV/c

**Next Step:** Generate more data at high momentum and retrain.

---

## ğŸ¯ Next Steps

### Immediate
1. âœ… **Complete** - Identify best model (SiLU activation, 0.21mm)
2. ğŸ”œ **Next** - Train architecture variants (tiny â†’ xlarge)
3. ğŸ”œ **Next** - Extend to full momentum range (up to 200 GeV/c)
4. ğŸ”œ **Next** - Export to ONNX for C++ deployment

### Medium Term
- Generate 1M+ training samples for production
- Multi-step extrapolation (multiple z planes)
- Uncertainty quantification (Bayesian dropout)
- Integration into LHCb Gaudi framework

### Long Term
- Neural ODEs for continuous-time modeling
- Transformer architecture for sequence modeling
- Proper PINN with ODE-integrated physics loss
- Active learning for data efficiency

---

## ğŸ“š Files Reference

| File | Purpose |
|------|---------|
| `python/generate_training_data.py` | Fast parallel data generation from RK4 |
| `python/train_analysis_models.py` | Train all model variants |
| `python/train_on_gpu.py` | General GPU training script |
| `models/analysis/mlp_act_silu.pt` | **Best model** - use this! |
| `condor/README.md` | HTCondor cluster usage guide |
| `../model_investigation.ipynb` | **Main analysis notebook** |

---

## ğŸ¤ Contributing

When adding new models:
1. Save in `.pt` format with full state dict
2. Include `_metadata.json` with training config
3. Update this README with results
4. Add entry to `experiment_log.csv` in `../experiments/`

---

**Last Updated:** January 2025  
**Model Version:** v1.0 (Analysis Complete)
