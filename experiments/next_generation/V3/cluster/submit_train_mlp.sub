# V3 MLP GPU Training Jobs - LONG category for full training
universe = vanilla
executable = /bin/bash
getenv = False
+UseOS = "el9"
+JobCategory = "long"

# GPU nodes
request_GPUs = 1
request_CPUs = 1
request_memory = 16G
request_disk = 20G

log = V3/cluster/logs/train_$(name)_$(Cluster).log
output = V3/cluster/logs/train_$(name)_$(Cluster).out
error = V3/cluster/logs/train_$(name)_$(Cluster).err

initialdir = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation

name = mlp_v3_shallow_256
arguments = "-c 'export HOME=/data/bfys/gscriven && source /data/bfys/gscriven/conda/etc/profile.d/conda.sh && conda activate TE && cd /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation && python V3/training/train_mlp.py --model mlp --data_path V3/data/training_mlp_v3.npz --hidden_dims 256 256 128 --name mlp_v3_shallow_256 --checkpoint_dir V3/trained_models --epochs 100 --batch_size 4096 --patience 20 --num_workers 0'"
queue 1

name = mlp_v3_shallow_512
arguments = "-c 'export HOME=/data/bfys/gscriven && source /data/bfys/gscriven/conda/etc/profile.d/conda.sh && conda activate TE && cd /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation && python V3/training/train_mlp.py --model mlp --data_path V3/data/training_mlp_v3.npz --hidden_dims 512 512 256 --name mlp_v3_shallow_512 --checkpoint_dir V3/trained_models --epochs 100 --batch_size 4096 --patience 20 --num_workers 0'"
queue 1

name = mlp_v3_deep_128
arguments = "-c 'export HOME=/data/bfys/gscriven && source /data/bfys/gscriven/conda/etc/profile.d/conda.sh && conda activate TE && cd /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation && python V3/training/train_mlp.py --model mlp --data_path V3/data/training_mlp_v3.npz --hidden_dims 128 128 128 128 64 --name mlp_v3_deep_128 --checkpoint_dir V3/trained_models --epochs 100 --batch_size 4096 --patience 20 --num_workers 0'"
queue 1

name = mlp_v3_deep_256
arguments = "-c 'export HOME=/data/bfys/gscriven && source /data/bfys/gscriven/conda/etc/profile.d/conda.sh && conda activate TE && cd /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation && python V3/training/train_mlp.py --model mlp --data_path V3/data/training_mlp_v3.npz --hidden_dims 256 256 256 256 128 --name mlp_v3_deep_256 --checkpoint_dir V3/trained_models --epochs 100 --batch_size 4096 --patience 20 --num_workers 0'"
queue 1
