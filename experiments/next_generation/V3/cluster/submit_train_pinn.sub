# V3 PINN GPU Training Jobs - Using el9 container on Debian12 GPU nodes
universe = vanilla
executable = /bin/bash
getenv = False
+UseOS = "el9"
+JobCategory = "short"

# GPU nodes - standard memory for most jobs
request_GPUs = 1
request_CPUs = 1
request_memory = 16G
request_disk = 20G

log = V3/cluster/logs/train_$(name)_$(Cluster).log
output = V3/cluster/logs/train_$(name)_$(Cluster).out
error = V3/cluster/logs/train_$(name)_$(Cluster).err

initialdir = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation

name = pinn_v3_res_256_col5
arguments = "-c 'export HOME=/data/bfys/gscriven && source /data/bfys/gscriven/conda/etc/profile.d/conda.sh && conda activate TE && cd /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation && python V3/training/train_pinn.py --config V3/training/configs/pinn_v3_res_256_col5.json'"
queue 1

name = pinn_v3_res_256_col10
arguments = "-c 'export HOME=/data/bfys/gscriven && source /data/bfys/gscriven/conda/etc/profile.d/conda.sh && conda activate TE && cd /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation && python V3/training/train_pinn.py --config V3/training/configs/pinn_v3_res_256_col10.json'"
queue 1

name = pinn_v3_res_256_col20
arguments = "-c 'export HOME=/data/bfys/gscriven && source /data/bfys/gscriven/conda/etc/profile.d/conda.sh && conda activate TE && cd /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation && python V3/training/train_pinn.py --config V3/training/configs/pinn_v3_res_256_col20.json'"
queue 1

# col50 needs more memory (was hitting 16GB limit)
request_memory = 32G
name = pinn_v3_res_256_col50
arguments = "-c 'export HOME=/data/bfys/gscriven && source /data/bfys/gscriven/conda/etc/profile.d/conda.sh && conda activate TE && cd /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation && python V3/training/train_pinn.py --config V3/training/configs/pinn_v3_res_256_col50.json'"
queue 1
