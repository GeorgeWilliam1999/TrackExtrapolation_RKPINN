# =============================================================================
# V5 Training Job Submission
# Trains 7 models: MLP + Quadratic + ZFrac + PDE-pure + PDE-hybrid + Comp-N8 + Comp-N16
#
# All models use the unified train_v5.py with JSON config files.
# Jobs are defined in v5_jobs.txt (one config name per line).
#
# Usage:
#   cd V5/cluster/
#   condor_submit submit_v5_training.sub
#
# Monitor:
#   condor_q -nobatch
#   condor_q -analyze <job_id>
# =============================================================================

universe = vanilla
executable = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V5/training/train_v5_wrapper.sh
arguments = $(CONFIG_NAME)

# Logging
output = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V5/cluster/logs/train_$(CONFIG_NAME)_$(Cluster).$(Process).out
error  = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V5/cluster/logs/train_$(CONFIG_NAME)_$(Cluster).$(Process).err
log    = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V5/cluster/logs/train_v5_$(Cluster).log

# Resources
request_gpus   = 1
request_cpus   = 4
request_memory = 32G
request_disk   = 50G

# Environment
+UseOS       = "el9"
+JobCategory = "long"
should_transfer_files = NO
getenv = True

# Queue all jobs from the job list file
queue CONFIG_NAME from /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V5/cluster/v5_jobs.txt
