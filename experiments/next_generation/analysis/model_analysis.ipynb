{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d110d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "# Add project paths\n",
    "PROJECT_ROOT = Path('/data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation')\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'models'))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'analysis'))\n",
    "\n",
    "# Import analysis modules\n",
    "from analyze_models import TrackExtrapolatorAnalyzer\n",
    "from physics_analysis import PhysicsAnalyzer\n",
    "from trajectory_visualizer import TrajectoryVisualizer\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6727b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODELS_DIR = PROJECT_ROOT / 'trained_models'\n",
    "DATA_PATH = PROJECT_ROOT / 'data_generation/data/training_50M.npz'\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'analysis/results'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Number of samples for analysis (use more for final analysis)\n",
    "N_ANALYSIS_SAMPLES = 100000\n",
    "\n",
    "print(f\"Models directory: {MODELS_DIR}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3592e900",
   "metadata": {},
   "source": [
    "## 1. Load Models and Data\n",
    "\n",
    "First, let's load all trained models and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the main analyzer\n",
    "analyzer = TrackExtrapolatorAnalyzer(\n",
    "    models_dir=MODELS_DIR,\n",
    "    data_path=DATA_PATH\n",
    ")\n",
    "\n",
    "# Load test data\n",
    "analyzer.load_data(n_samples=N_ANALYSIS_SAMPLES)\n",
    "\n",
    "# Load all trained models\n",
    "analyzer.load_all_models(pattern='*_v1')\n",
    "\n",
    "print(f\"\\nLoaded {len(analyzer.models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25386e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all models and their types\n",
    "model_names = list(analyzer.models.keys())\n",
    "\n",
    "# Categorize by type\n",
    "mlp_models = [m for m in model_names if 'mlp' in m.lower() and 'pinn' not in m.lower() and 'res' not in m.lower()]\n",
    "resmlp_models = [m for m in model_names if 'resmlp' in m.lower()]\n",
    "pinn_models = [m for m in model_names if 'pinn' in m.lower() and 'rkpinn' not in m.lower()]\n",
    "rkpinn_models = [m for m in model_names if 'rkpinn' in m.lower()]\n",
    "\n",
    "print(f\"Model Types:\")\n",
    "print(f\"  MLP: {len(mlp_models)}\")\n",
    "print(f\"  ResidualMLP: {len(resmlp_models)}\")\n",
    "print(f\"  PINN: {len(pinn_models)}\")\n",
    "print(f\"  RK-PINN: {len(rkpinn_models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17e378",
   "metadata": {},
   "source": [
    "## 2. Model Performance Overview\n",
    "\n",
    "Let's compute and display the performance statistics for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc7004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics for all models\n",
    "all_stats = analyzer.compute_statistical_summary(model_names)\n",
    "\n",
    "# Sort by position error\n",
    "sorted_stats = sorted(all_stats.items(), key=lambda x: x[1]['pos_mean'])\n",
    "\n",
    "# Display top 15 models\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Rank':<5} {'Model':<30} {'Type':<12} {'Params':>10} {'Pos Err (mm)':>12} {'Slope (mrad)':>12}\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for rank, (name, stats) in enumerate(sorted_stats[:15], 1):\n",
    "    print(f\"{rank:<5} {name:<30} {stats['model_type']:<12} {stats['parameters']:>10,} \"\n",
    "          f\"{stats['pos_mean']:>12.4f} {stats['slope_mean_mrad']:>12.4f}\")\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(f\"\\nüèÜ Best Model: {sorted_stats[0][0]}\")\n",
    "print(f\"   Position Error: {sorted_stats[0][1]['pos_mean']:.4f} ¬± {sorted_stats[0][1]['pos_std']:.4f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Group by model type\n",
    "colors = {'MLP': 'blue', 'ResidualMLP': 'green', 'PINN': 'red', 'RKPINN': 'orange'}\n",
    "\n",
    "for name, stats in all_stats.items():\n",
    "    model_type = stats['model_type']\n",
    "    if model_type == 'RK-PINN':\n",
    "        model_type = 'RKPINN'\n",
    "    color = colors.get(model_type, 'gray')\n",
    "    \n",
    "    # Position error vs parameters\n",
    "    axes[0].scatter(stats['parameters'], stats['pos_mean'], \n",
    "                   c=color, s=80, alpha=0.7, label=model_type)\n",
    "    \n",
    "    # Slope error vs parameters  \n",
    "    axes[1].scatter(stats['parameters'], stats['slope_mean_mrad'],\n",
    "                   c=color, s=80, alpha=0.7)\n",
    "    \n",
    "    # Position vs Slope error (trade-off)\n",
    "    axes[2].scatter(stats['pos_mean'], stats['slope_mean_mrad'],\n",
    "                   c=color, s=80, alpha=0.7)\n",
    "\n",
    "# Remove duplicate legend entries\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "axes[0].legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "axes[0].set_xlabel('Parameters')\n",
    "axes[0].set_ylabel('Position Error [mm]')\n",
    "axes[0].set_title('Position Error vs Model Size')\n",
    "axes[0].set_xscale('log')\n",
    "\n",
    "axes[1].set_xlabel('Parameters')\n",
    "axes[1].set_ylabel('Slope Error [mrad]')\n",
    "axes[1].set_title('Slope Error vs Model Size')\n",
    "axes[1].set_xscale('log')\n",
    "\n",
    "axes[2].set_xlabel('Position Error [mm]')\n",
    "axes[2].set_ylabel('Slope Error [mrad]')\n",
    "axes[2].set_title('Error Trade-off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee5d32",
   "metadata": {},
   "source": [
    "## 3. Trajectory Visualization\n",
    "\n",
    "Let's visualize how the models predict track trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ff8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top models from each category for visualization\n",
    "best_models = []\n",
    "\n",
    "# Best MLP\n",
    "mlp_sorted = [(n, all_stats[n]['pos_mean']) for n in mlp_models if n in all_stats]\n",
    "if mlp_sorted:\n",
    "    best_models.append(min(mlp_sorted, key=lambda x: x[1])[0])\n",
    "\n",
    "# Best ResidualMLP\n",
    "resmlp_sorted = [(n, all_stats[n]['pos_mean']) for n in resmlp_models if n in all_stats]\n",
    "if resmlp_sorted:\n",
    "    best_models.append(min(resmlp_sorted, key=lambda x: x[1])[0])\n",
    "\n",
    "# Best PINN\n",
    "pinn_sorted = [(n, all_stats[n]['pos_mean']) for n in pinn_models if n in all_stats]\n",
    "if pinn_sorted:\n",
    "    best_models.append(min(pinn_sorted, key=lambda x: x[1])[0])\n",
    "\n",
    "# Best RK-PINN\n",
    "rkpinn_sorted = [(n, all_stats[n]['pos_mean']) for n in rkpinn_models if n in all_stats]\n",
    "if rkpinn_sorted:\n",
    "    best_models.append(min(rkpinn_sorted, key=lambda x: x[1])[0])\n",
    "\n",
    "print(\"Best models per category:\")\n",
    "for m in best_models:\n",
    "    print(f\"  {m}: {all_stats[m]['pos_mean']:.4f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectory comparison\n",
    "fig = analyzer.plot_trajectory_comparison(\n",
    "    best_models,\n",
    "    n_tracks=4,\n",
    "    save_path=OUTPUT_DIR / 'trajectory_comparison.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e398903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residual distributions\n",
    "fig = analyzer.plot_trajectory_residuals(\n",
    "    best_models,\n",
    "    save_path=OUTPUT_DIR / 'residual_distributions.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705e8a1",
   "metadata": {},
   "source": [
    "## 4. Physics Constraint Analysis\n",
    "\n",
    "Now let's analyze whether the models correctly learn the underlying physics, particularly:\n",
    "- **ty conservation**: In a vertical magnetic field, the y-slope should be conserved\n",
    "- **Charge consistency**: Opposite charges should bend in opposite directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ty Conservation Analysis\n",
    "ty_results = analyzer.analyze_ty_conservation(\n",
    "    best_models,\n",
    "    save_path=OUTPUT_DIR / 'ty_conservation.png'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nty Conservation Metrics (lower = better physics learning):\")\n",
    "print(f\"{'Model':<30} {'Mean Œîty':>12} {'Std Œîty':>12} {'RMSE':>12}\")\n",
    "print(\"-\"*70)\n",
    "for name, metrics in ty_results.items():\n",
    "    print(f\"{name:<30} {metrics['mean_dty']*1000:>12.4f}mrad {metrics['std_dty']*1000:>12.4f}mrad {metrics['rmse_dty']*1000:>12.4f}mrad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge Consistency Analysis\n",
    "charge_results = analyzer.analyze_charge_consistency(\n",
    "    best_models,\n",
    "    save_path=OUTPUT_DIR / 'charge_consistency.png'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCharge Consistency Metrics:\")\n",
    "print(f\"{'Model':<30} {'Asymmetry':>12} {'q+ Err':>12} {'q- Err':>12}\")\n",
    "print(\"-\"*70)\n",
    "for name, metrics in charge_results.items():\n",
    "    print(f\"{name:<30} {metrics['asymmetry']:>12.4f} {metrics['pos_err_mean']:>12.4f}mm {metrics['neg_err_mean']:>12.4f}mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b60a49",
   "metadata": {},
   "source": [
    "## 5. Momentum-Dependent Performance\n",
    "\n",
    "Low momentum tracks bend more in the magnetic field and are harder to extrapolate accurately. Let's analyze how model performance varies with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum dependence analysis\n",
    "momentum_results = analyzer.analyze_momentum_dependence(\n",
    "    best_models,\n",
    "    n_bins=20,\n",
    "    save_path=OUTPUT_DIR / 'momentum_dependence.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035970fd",
   "metadata": {},
   "source": [
    "## 6. Advanced Physics Analysis: Lorentz Force\n",
    "\n",
    "The Lorentz force $\\vec{F} = q(\\vec{v} \\times \\vec{B})$ dictates how charged particles bend in a magnetic field:\n",
    "- $\\frac{d(tx)}{dz} \\propto \\frac{q}{p}$ (for vertical B field)\n",
    "- $\\frac{d(ty)}{dz} \\approx 0$ (ty conserved)\n",
    "\n",
    "Let's test whether models correctly capture this physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05056f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize physics analyzer\n",
    "physics = PhysicsAnalyzer()\n",
    "physics.load_data(DATA_PATH, n_samples=N_ANALYSIS_SAMPLES)\n",
    "\n",
    "# Load models\n",
    "for model_name in best_models:\n",
    "    physics.load_model(MODELS_DIR / model_name)\n",
    "\n",
    "print(f\"Loaded {len(physics.models)} models for physics analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e97c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorentz Force Analysis\n",
    "lorentz_results = physics.analyze_lorentz_force(\n",
    "    best_models,\n",
    "    save_path=OUTPUT_DIR / 'lorentz_force.png'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLorentz Force Learning Metrics:\")\n",
    "print(f\"{'Model':<30} {'Slope Ratio':>12} {'R¬≤':>12} {'Œîty Std':>12}\")\n",
    "print(\"-\"*70)\n",
    "for name, metrics in lorentz_results.items():\n",
    "    print(f\"{name:<30} {metrics['slope_ratio']:>12.4f} {metrics['dtx_vs_qop_r2']:>12.4f} {metrics['dty_std']*1000:>12.4f}mrad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase Space Analysis\n",
    "physics.analyze_phase_space(\n",
    "    best_models,\n",
    "    save_path=OUTPUT_DIR / 'phase_space.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systematic Error Analysis\n",
    "systematic_results = physics.analyze_systematic_errors(\n",
    "    best_models,\n",
    "    save_path=OUTPUT_DIR / 'systematic_errors.png'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSystematic Error Analysis:\")\n",
    "print(f\"{'Model':<30} {'X Bias':>12} {'X Random':>12} {'Bias/Random':>12}\")\n",
    "print(\"-\"*70)\n",
    "for name, metrics in systematic_results.items():\n",
    "    print(f\"{name:<30} {metrics['dx_bias']:>12.4f}mm {metrics['dx_random']:>12.4f}mm {metrics['bias_to_random_x']:>12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35166153",
   "metadata": {},
   "source": [
    "## 7. PINN vs MLP Deep Comparison\n",
    "\n",
    "Let's specifically examine whether physics-informed constraints (ty conservation, charge consistency) actually improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec466ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive PINN constraint analysis\n",
    "pinn_constraint_results = physics.analyze_pinn_constraints(\n",
    "    best_models,\n",
    "    save_path=OUTPUT_DIR / 'pinn_constraints.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall PINN vs MLP comparison\n",
    "comparison = analyzer.compare_pinn_vs_mlp(\n",
    "    save_path=OUTPUT_DIR / 'pinn_vs_mlp.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a695fa0",
   "metadata": {},
   "source": [
    "## 8. Summary and Conclusions\n",
    "\n",
    "Let's summarize the key findings from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"=\"*80)\n",
    "print(\"TRACK EXTRAPOLATOR MODEL ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Best overall model\n",
    "best_overall = sorted_stats[0]\n",
    "print(f\"\\nüèÜ BEST OVERALL MODEL: {best_overall[0]}\")\n",
    "print(f\"   Type: {best_overall[1]['model_type']}\")\n",
    "print(f\"   Parameters: {best_overall[1]['parameters']:,}\")\n",
    "print(f\"   Position Error: {best_overall[1]['pos_mean']:.4f} ¬± {best_overall[1]['pos_std']:.4f} mm\")\n",
    "print(f\"   Slope Error: {best_overall[1]['slope_mean_mrad']:.4f} ¬± {best_overall[1]['slope_std_mrad']:.4f} mrad\")\n",
    "\n",
    "# Best by category\n",
    "print(\"\\nüìä BEST BY CATEGORY:\")\n",
    "for category, models in [('MLP', mlp_models), ('ResidualMLP', resmlp_models), \n",
    "                          ('PINN', pinn_models), ('RK-PINN', rkpinn_models)]:\n",
    "    if models:\n",
    "        stats_list = [(n, all_stats[n]['pos_mean']) for n in models if n in all_stats]\n",
    "        if stats_list:\n",
    "            best = min(stats_list, key=lambda x: x[1])\n",
    "            print(f\"   {category}: {best[0]} ({best[1]:.4f} mm)\")\n",
    "\n",
    "# Physics learning assessment\n",
    "print(\"\\nüî¨ PHYSICS LEARNING ASSESSMENT:\")\n",
    "if lorentz_results:\n",
    "    best_lorentz = min(lorentz_results.items(), key=lambda x: abs(1 - x[1]['slope_ratio']))\n",
    "    print(f\"   Best Lorentz Force Learning: {best_lorentz[0]} (slope ratio: {best_lorentz[1]['slope_ratio']:.4f})\")\n",
    "    \n",
    "    best_ty = min(lorentz_results.items(), key=lambda x: x[1]['dty_std'])\n",
    "    print(f\"   Best ty Conservation: {best_ty[0]} (œÉ: {best_ty[1]['dty_std']*1000:.4f} mrad)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to JSON\n",
    "full_results = {\n",
    "    'model_statistics': all_stats,\n",
    "    'ty_conservation': ty_results if 'ty_results' in dir() else {},\n",
    "    'charge_consistency': charge_results if 'charge_results' in dir() else {},\n",
    "    'lorentz_force': lorentz_results if 'lorentz_results' in dir() else {},\n",
    "    'systematic_errors': systematic_results if 'systematic_results' in dir() else {},\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / 'full_analysis_results.json', 'w') as f:\n",
    "    json.dump(full_results, f, indent=2, default=lambda x: float(x) if hasattr(x, 'item') else x)\n",
    "\n",
    "print(f\"Results saved to {OUTPUT_DIR / 'full_analysis_results.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2282779",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analysis Complete!\n",
    "\n",
    "All plots have been saved to the output directory. Key findings:\n",
    "\n",
    "1. **Model Performance**: Review the ranking table to see which architectures perform best\n",
    "2. **Physics Constraints**: Check whether PINN models better preserve ty conservation and charge consistency\n",
    "3. **Momentum Dependence**: Low momentum tracks are harder - verify models handle this correctly\n",
    "4. **Systematic Errors**: Good models should have low bias and uncorrelated residuals\n",
    "\n",
    "For production use, select the model with the best trade-off between:\n",
    "- Position accuracy\n",
    "- Physics consistency\n",
    "- Model size (for inference speed)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
