# =============================================================================
# V4 Training Job Submission
# Trains 24 models: 8 MLP + 8 QuadraticResidual + 8 PINNZFracInput
#
# All models use the unified train_v4.py with JSON config files.
# Jobs are defined in v4_jobs.txt (one config name per line).
#
# Usage:
#   cd V4/cluster/
#   condor_submit submit_v4_training.sub
#
# Monitor:
#   condor_q -nobatch
#   condor_q -analyze <job_id>
# =============================================================================

universe = vanilla
executable = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V4/training/train_v4_wrapper.sh
arguments = $(CONFIG_NAME)

# Logging
output = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V4/cluster/logs/train_$(CONFIG_NAME)_$(Cluster).$(Process).out
error  = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V4/cluster/logs/train_$(CONFIG_NAME)_$(Cluster).$(Process).err
log    = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V4/cluster/logs/train_v4_$(Cluster).log

# Resources
request_gpus   = 1
request_cpus   = 4
request_memory = 32G
request_disk   = 50G

# Environment
+UseOS       = "el9"
+JobCategory = "long"
should_transfer_files = NO
getenv = True

# Queue all jobs from the job list file
queue CONFIG_NAME from /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/V4/cluster/v4_jobs.txt
