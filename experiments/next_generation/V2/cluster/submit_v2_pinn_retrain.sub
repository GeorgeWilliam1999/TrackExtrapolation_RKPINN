#===============================================================================
# HTCondor GPU Training - V2 PINN Retraining with Residual Architecture
#
# Retrains PINN and RK_PINN models with the new residual formulation that
# guarantees initial condition (IC) satisfaction.
#
# NEW PINN ARCHITECTURE:
#   Output = InitialState + z_frac * NetworkCorrection
#   - At z=0: Output = InitialState (IC automatically satisfied!)
#   - At z=1: Output = InitialState + NetworkCorrection
#   - Corrections scaled by z_frac, so network CANNOT ignore z
#
# This fixes the bug where old PINN ignored z_frac and learned constant outputs.
#
# GPU Resources at NIKHEF:
#   - wn-lot-008/009: 2x Tesla V100-PCIE-32GB each
#   - wn-pijl-002-007: 2-4x NVIDIA L40S (45GB) each
#
# Usage:
#   condor_submit submit_v2_pinn_retrain.sub
#
# Author: G. Scriven
# Date: January 2026
#===============================================================================

# Universe
universe = vanilla

# Executable
executable = run_training.sh

# GPU REQUIREMENTS - Accept ANY available GPU
request_gpus = 1

# Job requirements - LONG time limit, accept any GPU
+UseOS = "el9"
+JobCategory = "long"

# No GPU device restrictions - use whatever is available
# This allows jobs to run on V100, L40S, or any other GPU

# Resources (GPU training needs memory)
request_cpus = 4
request_memory = 32GB
request_disk = 10GB

# Maximum runtime: 24 hours (PINN training can be slow due to physics loss)
+MaxRuntime = 86400

# Working directory (NFS)
should_transfer_files = NO
initialdir = /data/bfys/gscriven/TE_stack/Rec/Tr/TrackExtrapolators/experiments/next_generation/cluster

# Logs
log = logs/v2_pinn_retrain_$(Cluster)_$(Process).log
output = logs/v2_pinn_retrain_$(Cluster)_$(Process).out
error = logs/v2_pinn_retrain_$(Cluster)_$(Process).err

# Notification
notification = Complete
notify_user = gscriven@nikhef.nl

#===============================================================================
# PINN V2 RETRAIN - With Residual Architecture (8 variants)
#
# New architecture features:
#   - Encoder processes only [x0, y0, tx0, ty0, qop] (5 inputs, NOT 6)
#   - z_frac used ONLY in skip connection (cannot be ignored)
#   - Output = baseline + z_frac * correction
#   - IC satisfied by construction
#===============================================================================

# PINN V2-1: Ultra-shallow single layer (256)
arguments = pinn tiny pinn_v2_single_256 --epochs 50 --batch_size 8192 --hidden_dims 256 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# PINN V2-2: Ultra-shallow single layer (512)
arguments = pinn tiny pinn_v2_single_512 --epochs 50 --batch_size 8192 --hidden_dims 512 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# PINN V2-3: Ultra-shallow single layer (1024)
arguments = pinn tiny pinn_v2_single_1024 --epochs 50 --batch_size 8192 --hidden_dims 1024 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# PINN V2-4: Shallow 2-layer (256-256)
arguments = pinn tiny pinn_v2_shallow_256 --epochs 50 --batch_size 8192 --hidden_dims 256 256 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# PINN V2-5: Shallow 2-layer (512-256)
arguments = pinn tiny pinn_v2_shallow_512_256 --epochs 50 --batch_size 8192 --hidden_dims 512 256 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# PINN V2-6: Shallow 2-layer (512-512)
arguments = pinn tiny pinn_v2_shallow_512 --epochs 50 --batch_size 8192 --hidden_dims 512 512 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# PINN V2-7: Shallow 2-layer (1024-256)
arguments = pinn tiny pinn_v2_shallow_1024_256 --epochs 50 --batch_size 8192 --hidden_dims 1024 256 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# PINN V2-8: Shallow 2-layer (1024-512)
arguments = pinn tiny pinn_v2_shallow_1024_512 --epochs 50 --batch_size 8192 --hidden_dims 1024 512 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

#===============================================================================
# RK_PINN V2 RETRAIN - With Residual Architecture (6 variants)
# Note: RK_PINN has inherent depth from 4-stage RK, so keep hidden networks shallow
#===============================================================================

# RK_PINN V2-1: Single hidden layer (256)
arguments = rk_pinn tiny rkpinn_v2_single_256 --epochs 50 --batch_size 4096 --hidden_dims 256 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# RK_PINN V2-2: Single hidden layer (512)
arguments = rk_pinn tiny rkpinn_v2_single_512 --epochs 50 --batch_size 4096 --hidden_dims 512 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# RK_PINN V2-3: Shallow 2-layer (256-256)
arguments = rk_pinn tiny rkpinn_v2_shallow_256 --epochs 50 --batch_size 4096 --hidden_dims 256 256 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# RK_PINN V2-4: Shallow 2-layer (512-256)
arguments = rk_pinn tiny rkpinn_v2_shallow_512_256 --epochs 50 --batch_size 4096 --hidden_dims 512 256 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# RK_PINN V2-5: Shallow 2-layer (512-512)
arguments = rk_pinn tiny rkpinn_v2_shallow_512 --epochs 50 --batch_size 4096 --hidden_dims 512 512 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

# RK_PINN V2-6: Shallow 2-layer (1024-256)
arguments = rk_pinn tiny rkpinn_v2_shallow_1024_256 --epochs 50 --batch_size 4096 --hidden_dims 1024 256 --lambda_pde 1.0 --lambda_ic 0.1
queue 1

#===============================================================================
# SUMMARY: 14 V2 PINN/RK_PINN models to retrain
#
# PINN:    8 models (single layer: 3, two layers: 5)
# RK_PINN: 6 models (single layer: 2, two layers: 4)
#
# Key changes from original V2:
#   - 50 epochs instead of 20 (physics learning takes longer)
#   - lambda_ic = 0.1 (IC is automatic, no need for high weight)
#   - Residual architecture guarantees IC = 0 at z=0
#
# Expected outcomes:
#   - IC error should be EXACTLY 0 (by construction)
#   - PDE loss should decrease during training
#   - Final accuracy may be similar to MLP but with physics guarantees
#===============================================================================
