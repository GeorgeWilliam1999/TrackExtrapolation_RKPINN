# Track Extrapolation ML Experiments

This directory contains organized experimental results for ML-based track extrapolation in LHCb.

---

## ğŸ“Š Summary of Results (January 2025)

### Best Model: **MLP with SiLU Activation**

| Metric | Value |
|--------|-------|
| **Mean Error** | 0.21 mm |
| **P95 Error** | 0.54 mm |
| **Speedup** | ~30,000Ã— vs RK8 |
| **Parameters** | 25,924 |

### Key Findings

1. âœ… **SiLU activation wins** (0.21mm vs 0.63mm tanh vs 0.77mm ReLU)
2. âŒ **PINN models failed** (physics loss formulation incorrect)
3. âŒ **Weighted loss made things worse** (too aggressive momentum weighting)
4. âœ… **Data-driven learning works** (implicit physics from examples)
5. âœ… **ONNX export ready** for C++ deployment

### Model Performance Timeline

| Date | Model | Mean Error | Notes |
|------|-------|------------|-------|
| 2024-11 | MLP v1 (tanh) | 1.48 mm | First working model |
| 2024-12 | PINN v1 | 1.28 mm | Physics loss helped (slightly) |
| 2024-12 | Weighted | 2.5+ mm | Made things worse |
| 2025-01 | MLP SiLU | **0.21 mm** | **Current best** |
| 2025-01 | PINN Î»=0.01 | 18.8 mm | Physics loss failed |
| 2025-01 | PINN Î»=0.2 | 328.9 mm | Catastrophic failure |

---

## ğŸ“‚ Directory Structure

```
experiments/
â”‚
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ experiment_log.csv              # Master log of all experiments
â”‚
â”œâ”€â”€ baseline/                       # Initial experiments
â”‚   â”œâ”€â”€ v1_positive_qop/            # Single charge training
â”‚   â”‚   â””â”€â”€ [models, plots, logs]
â”‚   â””â”€â”€ v2_both_charges/            # Full charge spectrum (production baseline)
â”‚       â””â”€â”€ [models, plots, logs]
â”‚
â”œâ”€â”€ architecture/                   # Network architecture studies
â”‚   â”œâ”€â”€ deeper_networks/            # 4-6 layer experiments
â”‚   â”œâ”€â”€ wider_networks/             # 256-512 neuron layers
â”‚   â””â”€â”€ skip_connections/           # ResNet-style architectures
â”‚
â”œâ”€â”€ momentum_studies/               # Momentum range experiments
â”‚   â”œâ”€â”€ low_p_05_2gev/              # Low momentum (hardest region)
â”‚   â”œâ”€â”€ mid_p_2_10gev/              # Medium momentum
â”‚   â””â”€â”€ high_p_10_100gev/           # High momentum (easiest)
â”‚
â”œâ”€â”€ physics_informed/               # PINN experiments
â”‚   â”œâ”€â”€ lorentz_loss/               # Lorentz force constraint (FAILED)
â”‚   â””â”€â”€ energy_conservation/        # Energy loss constraint
â”‚
â”œâ”€â”€ data_augmentation/              # Data sampling strategies
â”‚   â”œâ”€â”€ dense_grid/                 # Uniform grid sampling
â”‚   â””â”€â”€ random_sampling/            # Random phase space sampling
â”‚
â”œâ”€â”€ field_maps/                     # Magnetic field studies
â”‚   â”œâ”€â”€ simplified/                 # Simplified dipole model
â”‚   â””â”€â”€ simcond/                    # Full SimCond field map
â”‚
â”œâ”€â”€ weighted_loss/                  # Loss weighting experiments (FAILED)
â”‚   â”œâ”€â”€ README.md                   # Results documentation
â”‚   â”œâ”€â”€ train_weighted.py
â”‚   â”œâ”€â”€ train_weighted_v2.py
â”‚   â””â”€â”€ training_log.txt
â”‚
â”œâ”€â”€ onnx_export/                    # Model export for deployment
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ export_onnx.py
â”‚   â”œâ”€â”€ export_onnx_v2.py
â”‚   â”œâ”€â”€ mlp_full_domain.onnx        # Exported MLP model
â”‚   â”œâ”€â”€ mlp_full_domain_norm.json   # Normalization parameters
â”‚   â”œâ”€â”€ pinn_full_domain.onnx       # Exported PINN model
â”‚   â””â”€â”€ pinn_full_domain_norm.json
â”‚
â””â”€â”€ production/                     # Production-ready models
    â””â”€â”€ best_model/                 # Final model for deployment
```

---

## ğŸ”¬ Experiment Details

### 1. Baseline Experiments (`baseline/`)

**Goal:** Establish baseline MLP performance

| Version | Charge | Samples | Error | Notes |
|---------|--------|---------|-------|-------|
| v1 | + only | 50K | ~2 mm | Initial test |
| v2 | Â±both | 50K | 1.48 mm | Production baseline |

**Conclusion:** Training on both charges is essential for correct physics.

### 2. Architecture Studies (`architecture/`)

**Goal:** Find optimal network size

| Architecture | Layers | Params | Error | Status |
|--------------|--------|--------|-------|--------|
| tiny | 64-32 | 2,692 | - | Not trained |
| small | 128-64 | 9,796 | - | Not trained |
| **medium** | 128-128-64 | 25,924 | **0.21 mm** | âœ… Default |
| large | 256-256-128-64 | 140,228 | - | Not trained |
| xlarge | 512-512-256-128 | 536,836 | - | Not trained |

**Status:** Only medium architecture tested with SiLU. Others need training.

**Next Step:** Train all architectures to verify medium is optimal.

### 3. Momentum Studies (`momentum_studies/`)

**Goal:** Understand momentum-dependent performance

| Range | Samples | Typical Error | Notes |
|-------|---------|---------------|-------|
| 0.5-2 GeV | 10K | ~3-5 mm | Hardest (most bending) |
| 2-10 GeV | 20K | ~1-2 mm | Medium difficulty |
| 10-100 GeV | 20K | ~0.5 mm | Easiest (straight) |

**Key Finding:** Low momentum tracks are hardest due to strong magnetic bending.

### 4. Physics-Informed (`physics_informed/`)

**Goal:** Improve generalization with physics constraints

#### Lorentz Loss (FAILED âŒ)

Physics loss components:
```python
# Position consistency (wrong assumption!)
L_pos_x = |x_out - (x_in + dz Ã— tx_in)|Â²
L_pos_y = |y_out - (y_in + dz Ã— ty_in)|Â²

# Bending constraint (oversimplified!)
L_bend = |Î”tx_out - Îº Ã— q/p|Â²

# Vertical penalty
L_ty = |Î”ty_out|Â²
```

**Results:**

| Î» (physics weight) | Mean Error | Notes |
|--------------------|------------|-------|
| 0.00 (MLP) | 0.21 mm | Baseline |
| 0.01 | 18.8 mm | 90Ã— worse |
| 0.05 | 106.7 mm | 500Ã— worse |
| 0.10 | 197.2 mm | 940Ã— worse |
| 0.20 | 328.9 mm | 1570Ã— worse |

**Root Cause:** Physics loss assumes straight-line propagation between start/end points, which is physically wrong in a non-uniform magnetic field. Higher Î» enforces wrong constraints harder â†’ worse performance.

**Recommendation:** Abandon current PINN approach OR redesign with Neural ODEs.

### 5. Weighted Loss (`weighted_loss/`)

**Goal:** Improve low-momentum performance via loss weighting

```python
weights = (P_max / P)^power  # Higher weight for low momentum
loss = (weights * MSE).mean()
```

| Power | Low-p Error | High-p Error | Total | Notes |
|-------|-------------|--------------|-------|-------|
| 0 (uniform) | 2.5 mm | 1.0 mm | 1.48 mm | Baseline |
| 1 | 2.2 mm | 1.5 mm | 1.8 mm | Worse overall |
| 2 | 2.0 mm | 2.2 mm | 2.1 mm | Much worse |

**Conclusion:** Aggressive momentum weighting hurts high-p performance more than it helps low-p. Not worth the trade-off.

### 6. ONNX Export (`onnx_export/`)

**Goal:** Export models for C++ inference

**Status:** âœ… Working

Files:
- `mlp_full_domain.onnx` - Best MLP model
- `mlp_full_domain_norm.json` - Input/output normalization
- `pinn_full_domain.onnx` - PINN model (deprecated)

Usage in C++:
```cpp
#include <onnxruntime/core/session/onnxruntime_cxx_api.h>
// See ml_models/src/TrackMLPExtrapolator.cpp
```

---

## ğŸ“‹ Experiment Log Format

The `experiment_log.csv` file tracks all experiments:

```csv
date,experiment,model,architecture,activation,epochs,samples,mean_error,p95_error,notes
2025-01-13,activation_study,mlp_act_silu,128-128-64,silu,2000,50000,0.207,0.543,Best model
2025-01-13,pinn_study,pinn_lambda_0_01,128-128-64,tanh,2000,50000,18.85,47.23,Physics loss failed
```

Add new experiments here for tracking.

---

## ğŸ¯ Lessons Learned

### What Worked âœ…
1. **SiLU activation** - 3Ã— better than tanh with no extra cost
2. **Data-driven learning** - Let the network learn physics from data
3. **Medium architecture** - 128-128-64 is good balance
4. **Both charges** - Essential for correct physics

### What Failed âŒ
1. **Physics-informed loss** - Oversimplified constraints hurt more than help
2. **Momentum weighting** - Trade-off not worthwhile
3. **Very deep networks** - No clear benefit (needs more testing)

### What Needs Testing â³
1. **Architecture sweep** - tiny to xlarge
2. **Learning rate schedules** - Cosine annealing, warmup
3. **Neural ODEs** - Proper physics integration
4. **Bayesian networks** - Uncertainty quantification

---

## ğŸ“š References

- [Model Investigation Notebook](../model_investigation.ipynb) - Detailed analysis
- [ML Models README](../ml_models/README.md) - Training documentation
- [Main README](../README.md) - Project overview

---

**Last Updated:** January 2025
